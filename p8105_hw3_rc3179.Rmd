---
title: "Homework 3"
author: "RuiJun Chen"
date: "10/14/2019"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.heigh = 6,
  out.width = "90%"
  )

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1
```{r}
library(p8105.datasets)
data("instacart")
```

The Instacart dataset shows that there are a total of `r instacart %>% nrow()` observations/rows across `r instacart %>% pull(order_id) %>% n_distinct()` unique orders placed on Instacart. Each observation or row represents an item order, and there are `r instacart %>% ncol()` variables or columns which include `r instacart %>% tbl_vars()`. These variables include information on when the items were ordered, which user ordered it, how often it has been reordered, along with information on the item itself such as the name or department/aisle it is in. There are `r instacart %>% pull(department) %>% n_distinct()` unique departments from `r instacart %>% pull(department) %>% min()` to `r instacart %>% pull(department) %>% max()`. There are a total of `r instacart %>% pull(product_id) %>% n_distinct()` unique products available, with orders placed between the hours of `r instacart %>% pull(order_hour_of_day) %>% min()` and `r instacart %>% pull(order_hour_of_day) %>% max()`


```{r}
instacart %>% 
  group_by(aisle) %>% 
  summarize(n_orders = n()) %>% 
  arrange(desc(n_orders))
```
There are a total of `r instacart %>% pull(aisle) %>% n_distinct()` aisles and fresh vegetables and fresh fruits, respectively, are the top 2 aisles which have the most items ordered from them.

```{r}
instacart %>% 
  group_by(aisle) %>% 
  summarize(n_orders = n()) %>% 
  filter(n_orders > 10000) %>% 
  ggplot(aes(x = aisle, y = n_orders)) +
  geom_col() +
  labs(title = "Number of items ordered in each aisle", caption = "(min 10000 items), arranged alphabetically") +
  theme(axis.text.x = element_text(angle=90))
```

Table of 3 most popular items in aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
```{r}
instacart %>% 
  filter(aisle == 'baking ingredients' | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>% 
  group_by(aisle, product_name) %>% 
  summarize(n_orders = n()) %>% 
  arrange(desc(n_orders)) %>% 
  mutate(rank = rank(desc(n_orders))) %>% 
  filter(rank <= 3) %>% 
  knitr::kable()
```

```{r}
instacart %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour_of_day = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour_of_day
  ) %>% 
  knitr::kable()
```

## Problem 2

Cleaning the data to format variable names, focus on "Overall Health", including only "Excellent" to "Poor" responses, and organizing as factors ordered from "Poor" to "Excellent"
```{r}
data("brfss_smart2010")
brfss_smart2010 = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health" & 
           (response == "Excellent" | response == "Very good" |
              response == "Good" | response == "Fair" | response == "Poor")) %>% 
  mutate(
    response = factor(response),
    response = fct_relevel(response, "Poor", "Fair", "Good", "Very good")
  )

brfss_smart2010 
```


In 2002, which states were observed at 7 or more locations? What about in 2010?
```{r}
brfss_smart2010 %>% 
  filter(year == 2002) %>% 
  group_by(locationabbr, locationdesc) %>% 
  summarize(n = n_distinct(locationdesc)) %>% 
  count(locationabbr) %>% 
  filter(n >= 7)
```
In 2002, CT, FL, MA, NC, NJ, and PA were observed at 7 or more locations


```{r}
brfss_smart2010 %>% 
  filter(year == 2010) %>% 
  group_by(locationabbr, locationdesc) %>% 
  summarize(n = n_distinct(locationdesc)) %>% 
  count(locationabbr) %>% 
  filter(n >= 7)
```
In 2010, CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA were observed at 7 or more locations


Making spaghetti plot of average value over time within a state
```{r, fig.height=12}
brfss_smart2010 %>% 
  filter(response == "Excellent") %>% 
  select(year, locationabbr, response, data_value) %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_data_value = mean(data_value)) %>% 
  ggplot(aes(x = year, y = mean_data_value, color = locationabbr)) + 
  geom_line(aes(group = locationabbr)) +
  labs(title = "Average data value for each state over time", colour = "State")
```


Making two-panel plot for 2006 and 2010 with distribution of data_value for responses among locations in NY state
```{r}
brfss_smart2010 %>% 
  filter(locationabbr == "NY" & (year == 2006 | year == 2010)) %>% 
  ggplot(aes(x = response, y = data_value)) + 
  geom_point() +
  facet_grid(~year)
```


